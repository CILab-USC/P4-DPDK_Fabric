{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a519f73-cdd2-4b28-a231-a2064f5e2191",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 1 - Creating a Slice with a P4-DPDK Pipeline\n",
    "<div style=\"text-align: justify;\">\n",
    "This lab will walk you through creating an experiment that contains a P4-DPDK programmable pipeline. Specifically, the experiment deploys a slice in a single site with one node: server1. The topology is shown in the figure below. The lab provides an introduction to DPDK, a software-based packet processing acceleration tool. It demonstrates how to build a topology using namespaces and provides an explanation of scripts needed to build a P4-DPDK pipeline. </div>\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./labs_files/lab1/figs/0_00_fabric_topology.png\" width=\"550px\"><be>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e30c2-6ea9-45f7-b196-fb09b2a59d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f79baa-a4d4-4b64-8183-176b6964ee44",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "The process of receiving and handling network packets involves several steps, each of which contributes to the overall system performance. Accelerating packet processing while minimizing overhead is crucial for achieving optimal network throughput. Before packet processing accelerators, a standard Network Interface Card (NIC) receives a data packet (e.g., from the network cable), and triggers an interrupt. This interrupt is a signal sent to the operating system (OS) to inform it that data has arrived. The OS then processes this interrupt and identifies the memory location where the packet is stored. This location is typically in the system’s Random Access Memory (RAM). The network stack is a software component within the OS responsible for handling network-related tasks. It includes protocols, drivers, and other networking functionalities. Once the OS knows the packet’s location in memory, it transfers the packet to the network stack. This transfer involves copying the packet data from the NIC’s buffer to the network stack’s buffer. To deliver the packet to the correct user-level application (e.g., a web browser or email client), the network stack relies on system calls [<a href=\"#References\">1</a>]. </div>  <br>\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "While the above steps of standard packet processing shown in Figure 1 (a) are necessary for proper packet handling, they come at a cost. The additional processing involved in interrupt handling, memory copying, and system calls creates overhead. To mitigate this, modern systems use techniques like interrupt moderation, zero-copy networking, and kernel bypass mechanisms to minimize the impact of overhead on network performance. </div>   <br>\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "The Data Plane Development Kit (DPDK) is a software packet processing acceleration tool that consists of a collection of libraries and drivers that support packet processing within the user space while bypassing the kernel as shown in Figure 1 (b). With DPDK, the ports of the NIC do not rely on the in-kernel drivers. Instead, a NIC that supports DPDK is managed by DPDK drivers that operate as a Poll Mode Driver (PMD). It receives, classifies, and delivers packets as it consistently polls for incoming packets [<a href=\"#References\">2</a>]. This approach minimizes interrupt services overhead and improves performance. DPDK functionalities can also run on multiple cores with specific tasks running on each core using core affinity which prevents task switching among different cores and therefore enhances performance [<a href=\"#References\">1</a>]. </div>   <br>\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "  <img src=\"./labs_files/lab1/figs/0_intro_1_dpdk.png\" width=\"550\" style=\"display: block; margin: 0 auto;\">\n",
    "  <figcaption>Figure 1. Software packet processing. (a) standard packet processing (interrupt-based), (b) kernel-bypass packet processing (polling mode) [<a href=\"#References\">2</a>].</figcaption>\n",
    "</figure>\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "In network processing, both the CPU and the NIC frequently require access to data stored in memory such as cache and Dynamic Random Access Memory (DRAM). To optimize memory access, DPDK supports the use Hugepage and memory pools. To serve memory management purposes, DPDK swiftly moves data into the cache to prevent CPU overheads [<a href=\"#References\">3</a>]. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569df5c-9413-49b3-9ba3-adbd318c937a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DPDK pipeline model\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "The DPDK Packet Framework allows the implementation of accelerated packet processing with great flexibility. This framework required the use of a DPDK library (librte_pipeline) which provides a methodology for building a programmable pipeline tailored to serve a specific application [<a href=\"#References\">1</a>]. These pipelines act as modular building blocks that can be interconnected through packet queues to create entire network applications. See Figure 2. A DPDK pipeline has three main components: input ports, tables, and output ports. Each pipeline can be instantiated multiple times, with each instance mapped to a different CPU thread [<a href=\"#References\">4</a>]. </div>   <br> \n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "  <img src=\"./labs_files/lab1/figs/0_intro_2_pipeline.png\" width=\"550\" style=\"display: block; margin: 0 auto;\">\n",
    "  <figcaption>Figure 2. DPDK packet framework pipeline block [<a href=\"#References\">5</a>].</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235c1c1-3916-447b-b749-cdc3ca2fc1a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## P4 programming\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "Although DPDK is based on C programming, writing in P4 is generally considered more straightforward. P4 is a programming language to control the packet processing within the data plane of programmable forwarding elements, such as hardware or software switches, network interface cards, routers, and various network devices. Although initially designed for programmable switches, P4's application has expanded to be compatible with a diversity of devices called P4 targets, including SmartNICs. P4 is specifically designed to program the data plane of the target. The P4 code is written by the user in a specific architecture to ensure compatibility with the target. Afterward, the P4 code is ready to be compiled so that it can be executed by the target [<a href=\"#References\">6</a>]. </div>   <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea78be-6881-478c-b90b-dca327194b92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## P4-DPDK compiler\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "The Software Switch (SWX) pipeline integrates DPDK performance with the flexibility of the P4 language. It serves as a tool for developing software switches or data plane applications. Moreover, it can be combined with the open-source P4 compiler p4c-dpdk. This enables the translation of P4 programs to the DPDK SWX API, allowing them to run efficiently on multi-core CPUs. The primary output of the p4c-dpdk compiler given a P4 code is the specifications file (.spec). This file is needed to configure the DPDK pipeline. Subsequently, a C code is generated from the .spec file. This code includes C functions corresponding to each action and control block. A C compiler then generates a shared object (.so) from the C code. Finally, the shared object is needed to execute the application [<a href=\"#References\">7</a>]. </div>   <br> \n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "  <img src=\"./labs_files/lab1/figs/0_intro_3_p4dpdk.png\" width=\"550\" style=\"display: block; margin: 0 auto;\">\n",
    "  <figcaption>Figure 3. The p4c-dpdk workflow.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5c2c5-fda1-4e98-891d-28dd574125e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Memory in DPDK\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "Memory management is very important to maintain performance measures. DPDK supports various memory management features such as Hugepages, Non-uniform Memory Access (NUMA) nodes pinning, and memory pools [<a href=\"#References\">8</a>]. </div>   <br> \n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "A hugepage is a memory management technique used in modern computer systems to improve performance by using larger memory blocks (pages) than the default page size. \n",
    "When the DPDK application initializes and requests a certain number of hugepages, the operating system will reserve a large block of memory and allocate it to the application. Hugepage reservation is required in packet processing applications due to the large memory pool allocation used for packet buffers. If regular memory is used instead, applications using DPDK would experience significant performance degradation due to the high rate of accessed memory location misses. </div>   <br> \n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "NUMA node pinning is a technique used in computer systems with NUMA architecture to optimize performance by controlling how processes and memory are allocated. In a NUMA system, CPU cores are grouped into nodes, with each node having its own dedicated memory that is physically close to the running CPU cores. A general representation of the system is shown in Figure 4. Memory management features offered by DPDK make it less probable to write a poorly performing user application by including APIs where NUMA nodes have to be specified to run the applications. Therefore, pinned NUMA nodes to CPU cores are configured for every operation being held by the system. </div>   <br> \n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "  <img src=\"./labs_files/lab1/figs/0_intro_4_numa.png\" width=\"500\" style=\"display: block; margin: 0 auto;\">\n",
    "  <figcaption>Figure 4. NUMA node pinning [<a href=\"#References\">8</a>].</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b5308-1775-4cfe-9f4f-eb336a851337",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 1:  Configuring the environment\n",
    "\n",
    "Before running this notebook, you will need to configure your environment using the [Configure Environment](../../../configure_and_validate.ipynb) notebook. Please stop here, open and run that notebook, then return to this notebook.\n",
    "\n",
    "If you are using the FABRIC JupyterHub many of the environment variables will be automatically configured for you.  You will still need to set your bastion username, upload your bastion private key, and set the path to where you put your bastion private key. Your bastion username and private key should already be in your possession.  \n",
    "\n",
    "If you are using the FABRIC API outside of the JupyterHub you will need to configure all of the environment variables. Defaults below will be correct in many situations but you will need to confirm your configuration.  If you have questions about this configuration, please contact the FABRIC admins using the [FABRIC User Forum](https://learn.fabric-testbed.net/forums/) \n",
    "\n",
    "More information about accessing your experiments through the FABRIC bastion hosts can be found [here](https://learn.fabric-testbed.net/knowledge-base/logging-into-fabric-vms/).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b571c06-bfd5-464a-acf4-d28845c8e840",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Importing the FABlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9c3ea6-f0b5-4e34-9a4c-82785ff386c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2913e89-4188-4ebf-a24c-01cedd16540b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Creating the experiment slice\n",
    "\n",
    "The following creates a node with basic compute and networking capabilities. You build a slice by creating a new slice and adding resources to the slice. After you build the slice, you must submit a request for the slice to be instantiated.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161198e4-00b0-4994-9de8-28e8bfb16cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.1: Creating a slice\n",
    "The code below creates a new slice with the name \"P4DPDK_lab1_vnic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c97d810-ac6a-4c04-892d-f0ddbe69954b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice = fablib.new_slice(name=\"P4DPDK_lab1_vnic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f228eb-d12b-4644-bbc4-df2e34bbdce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.2: Defining the sites\n",
    "The code below requests a random site from FABRIC based on the condition that the following resources are available:\n",
    "\n",
    "<ul>\n",
    "    <li> 4 CPU cores</li>\n",
    "    <li> 8GB RAM </li>\n",
    "    <li> 20GB disc size\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28e0cf1-241d-4257-afbf-6aa44989d995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected site is MAX\n"
     ]
    }
   ],
   "source": [
    "site1= fablib.get_random_sites(count=1, filter_function=lambda x: x['cores_available'] > 4 and x['ram_available'] > 8 and x['disk_available'] > 20)[0]\n",
    "\n",
    "print (f'The selected site is {site1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71fead-a091-4af0-95ec-bb264c016c43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.3: Creating the nodes\n",
    "The code below creates one node (server1) which uses the following:\n",
    "<ul>\n",
    "    <li> 4 CPU cores</li>\n",
    "    <li> 8GB RAM </li>\n",
    "    <li> 20GB disc size </li>\n",
    "    <li> Image: Ubuntu 20.04\n",
    "</ul>\n",
    "\n",
    "server1 will be created in site1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7713728b-2740-4e72-b5dd-7d3963012536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server1 = slice.add_node(name=\"server1\", \n",
    "                      site=site1, \n",
    "                      cores=4, \n",
    "                      ram=8, \n",
    "                      disk=20, \n",
    "                      image='default_ubuntu_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab345c-d68e-440d-9fda-03d67472f1ca",
   "metadata": {},
   "source": [
    "### Step 3.4: Submitting the slice\n",
    "The code below submits the slice. \n",
    "By default, the submit function will block until the node is ready and will display the progress of your slice being built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e706c53c-7a38-4615-a86e-e8944197921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retry: 9, Time: 205 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_35a4d tr:nth-child(even) {\n",
       "  background: #dbf3ff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_35a4d tr:nth-child(odd) {\n",
       "  background: #ffffff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_35a4d caption {\n",
       "  text-align: center;\n",
       "  font-size: 150%;\n",
       "}\n",
       "#T_35a4d_row0_col0, #T_35a4d_row0_col1, #T_35a4d_row1_col0, #T_35a4d_row1_col1, #T_35a4d_row2_col0, #T_35a4d_row2_col1, #T_35a4d_row3_col0, #T_35a4d_row3_col1, #T_35a4d_row4_col0, #T_35a4d_row4_col1, #T_35a4d_row5_col0 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "  background-color: ;\n",
       "}\n",
       "#T_35a4d_row5_col1 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "  background-color: #c3ffc4;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_35a4d\">\n",
       "  <caption>Slice</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row0_col0\" class=\"data row0 col0\" >ID</td>\n",
       "      <td id=\"T_35a4d_row0_col1\" class=\"data row0 col1\" >7a33bf92-fc75-4525-8ec5-2d52d40c3c3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row1_col0\" class=\"data row1 col0\" >Name</td>\n",
       "      <td id=\"T_35a4d_row1_col1\" class=\"data row1 col1\" >P4DPDK_lab1_vnic_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row2_col0\" class=\"data row2 col0\" >Lease Expiration (UTC)</td>\n",
       "      <td id=\"T_35a4d_row2_col1\" class=\"data row2 col1\" >2024-09-21 17:22:38 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row3_col0\" class=\"data row3 col0\" >Lease Start (UTC)</td>\n",
       "      <td id=\"T_35a4d_row3_col1\" class=\"data row3 col1\" >2024-09-20 17:22:38 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row4_col0\" class=\"data row4 col0\" >Project ID</td>\n",
       "      <td id=\"T_35a4d_row4_col1\" class=\"data row4 col1\" >8eaa3ec2-65e7-49a3-8c09-e1761141a6ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_35a4d_row5_col0\" class=\"data row5 col0\" >State</td>\n",
       "      <td id=\"T_35a4d_row5_col1\" class=\"data row5 col1\" >StableOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7c6e4c5c1910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b0cfa caption {\n",
       "  text-align: center;\n",
       "  font-size: 150%;\n",
       "  caption-side: top;\n",
       "}\n",
       "#T_b0cfa th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b0cfa tr:nth-child(even) {\n",
       "  background: #ffffff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_b0cfa tr:nth-child(odd) {\n",
       "  background: #dbf3ff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_b0cfa .level0 {\n",
       "  border: 1px black solid !important;\n",
       "  background: #ffffff;\n",
       "  color: #231f20;\n",
       "}\n",
       "#T_b0cfa_row0_col0, #T_b0cfa_row0_col1, #T_b0cfa_row0_col2, #T_b0cfa_row0_col3, #T_b0cfa_row0_col4, #T_b0cfa_row0_col5, #T_b0cfa_row0_col6, #T_b0cfa_row0_col7, #T_b0cfa_row0_col8, #T_b0cfa_row0_col9, #T_b0cfa_row0_col10, #T_b0cfa_row0_col13, #T_b0cfa_row0_col14, #T_b0cfa_row0_col15 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "}\n",
       "#T_b0cfa_row0_col11 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "  background-color: #c3ffc4;\n",
       "}\n",
       "#T_b0cfa_row0_col12 {\n",
       "  text-align: left;\n",
       "  border: 1px #231f20 solid !important;\n",
       "  overwrite: False;\n",
       "  background-color: ;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b0cfa\">\n",
       "  <caption>Nodes</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b0cfa_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_b0cfa_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_b0cfa_level0_col2\" class=\"col_heading level0 col2\" >Cores</th>\n",
       "      <th id=\"T_b0cfa_level0_col3\" class=\"col_heading level0 col3\" >RAM</th>\n",
       "      <th id=\"T_b0cfa_level0_col4\" class=\"col_heading level0 col4\" >Disk</th>\n",
       "      <th id=\"T_b0cfa_level0_col5\" class=\"col_heading level0 col5\" >Image</th>\n",
       "      <th id=\"T_b0cfa_level0_col6\" class=\"col_heading level0 col6\" >Image Type</th>\n",
       "      <th id=\"T_b0cfa_level0_col7\" class=\"col_heading level0 col7\" >Host</th>\n",
       "      <th id=\"T_b0cfa_level0_col8\" class=\"col_heading level0 col8\" >Site</th>\n",
       "      <th id=\"T_b0cfa_level0_col9\" class=\"col_heading level0 col9\" >Username</th>\n",
       "      <th id=\"T_b0cfa_level0_col10\" class=\"col_heading level0 col10\" >Management IP</th>\n",
       "      <th id=\"T_b0cfa_level0_col11\" class=\"col_heading level0 col11\" >State</th>\n",
       "      <th id=\"T_b0cfa_level0_col12\" class=\"col_heading level0 col12\" >Error</th>\n",
       "      <th id=\"T_b0cfa_level0_col13\" class=\"col_heading level0 col13\" >SSH Command</th>\n",
       "      <th id=\"T_b0cfa_level0_col14\" class=\"col_heading level0 col14\" >Public SSH Key File</th>\n",
       "      <th id=\"T_b0cfa_level0_col15\" class=\"col_heading level0 col15\" >Private SSH Key File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b0cfa_row0_col0\" class=\"data row0 col0\" >dd8d00ce-0eda-4476-b82d-4eec26532504</td>\n",
       "      <td id=\"T_b0cfa_row0_col1\" class=\"data row0 col1\" >server1</td>\n",
       "      <td id=\"T_b0cfa_row0_col2\" class=\"data row0 col2\" >4</td>\n",
       "      <td id=\"T_b0cfa_row0_col3\" class=\"data row0 col3\" >8</td>\n",
       "      <td id=\"T_b0cfa_row0_col4\" class=\"data row0 col4\" >100</td>\n",
       "      <td id=\"T_b0cfa_row0_col5\" class=\"data row0 col5\" >default_ubuntu_20</td>\n",
       "      <td id=\"T_b0cfa_row0_col6\" class=\"data row0 col6\" >qcow2</td>\n",
       "      <td id=\"T_b0cfa_row0_col7\" class=\"data row0 col7\" >max-w1.fabric-testbed.net</td>\n",
       "      <td id=\"T_b0cfa_row0_col8\" class=\"data row0 col8\" >MAX</td>\n",
       "      <td id=\"T_b0cfa_row0_col9\" class=\"data row0 col9\" >ubuntu</td>\n",
       "      <td id=\"T_b0cfa_row0_col10\" class=\"data row0 col10\" >2001:468:c00:ffc4:f816:3eff:fe4f:3192</td>\n",
       "      <td id=\"T_b0cfa_row0_col11\" class=\"data row0 col11\" >Active</td>\n",
       "      <td id=\"T_b0cfa_row0_col12\" class=\"data row0 col12\" ></td>\n",
       "      <td id=\"T_b0cfa_row0_col13\" class=\"data row0 col13\" >ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:468:c00:ffc4:f816:3eff:fe4f:3192</td>\n",
       "      <td id=\"T_b0cfa_row0_col14\" class=\"data row0 col14\" >/home/fabric/work/fabric_config/slice_key.pub</td>\n",
       "      <td id=\"T_b0cfa_row0_col15\" class=\"data row0 col15\" >/home/fabric/work/fabric_config/slice_key</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7c6e5441c950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfa5ff-9374-4823-9ea0-09f045a91684",
   "metadata": {},
   "source": [
    "# Step 4: Installing the required packages\n",
    "In this step, we will install the required packages to run the lab. Specifically, we will install the DPDK library, the P4 compiler (p4c), and all needed dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c40316-489b-428d-82de-eb92e87c87dc",
   "metadata": {},
   "source": [
    "### Step 4.1 Getting the server node\n",
    "The command below gets the fablib node that server1 is associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61333554-ef05-480e-bee6-c2a035213b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "server1 = slice.get_node(name=\"server1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6f042-3232-4245-9a5b-9e163b1bb8f4",
   "metadata": {},
   "source": [
    "### Step 4.2 NAT64 setup\n",
    "The code below checks if an IPv6 address is available to set up NAT64. We will upload the script [scripts/nat64.sh](./scripts/nat64.sh) to the all servers and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00430e7b-472e-4d5b-a81d-03dfaaec14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv6Address\n",
    "\n",
    "if type(ip_address(server1.get_management_ip())) is IPv6Address:\n",
    "    server1.upload_file('scripts/nat64.sh', 'nat64.sh')\n",
    "    stdout, stderr = server1.execute(f'chmod +x nat64.sh && ./nat64.sh', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c187536-f87c-47ae-9ced-9cf234f70c45",
   "metadata": {},
   "source": [
    "### Step 4.3 Installing dependencies\n",
    "The code below installs packages that are prerequisites to the upcoming installations and needed to run the lab experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d516e3-323e-44c7-bec8-45a2d48a0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server1.execute(f'sudo apt-get update', quiet = True)\n",
    "stdout, stderr = server1.execute(f'sudo apt-get install -y build-essential python3-pip python3-pyelftools libnuma-dev pkg-config net-tools', quiet = True)\n",
    "stdout, stderr = server1.execute(f'sudo pip3 install meson ninja', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea007d60-a00c-4c48-aab9-a9dc3ef16931",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 4.4 Installing DPDK\n",
    "The code below downloads, builds, and installs DPDK on all servers. In this lab, we are building a modified version of DPDK in which we enabled logs in the terminal to have a better understanding of the behavior of the built pipeline. Note that printing out logs on the terminal degrades performance. Therefore, with applications where high performance is needed, logging should be disabled.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a161e7-65b6-403f-8e3e-8a8d1fe19a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server1.execute(f'git clone http://dpdk.org/git/dpdk', quiet = True)\n",
    "stdout, stderr = server1.execute(f'cd dpdk/lib/pipeline/ &&  sudo rm rte_swx_pipeline.c && sudo rm rte_swx_pipeline_internal.h', quiet = True)\n",
    "server1.upload_file('scripts/rte_swx_pipeline.c','/home/ubuntu/dpdk/lib/pipeline/rte_swx_pipeline.c')\n",
    "server1.upload_file('scripts/rte_swx_pipeline_internal.h','/home/ubuntu/dpdk/lib/pipeline/rte_swx_pipeline_internal.h')\n",
    "stdout, stderr = server1.execute(f'cd dpdk &&  sudo meson build && cd build && sudo ninja && sudo ninja install && sudo ldconfig', quiet = True)\n",
    "stdout, stderr = server1.execute(f'cd dpdk/examples/pipeline && sudo make', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3663be2-ae7e-4352-9659-4ac52b2b32b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 4.5 Install p4c\n",
    "The code below downloads and installs the p4c compiler needed to compile the p4 code into a DPDK pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf0857a2-7ec6-4ed3-92c4-6eed2e697d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server1.execute('source /etc/lsb-release && echo \"deb http://download.opensuse.org/repositories/home:/p4lang/xUbuntu_${DISTRIB_RELEASE}/ /\" | sudo tee /etc/apt/sources.list.d/home:p4lang.list && curl -fsSL https://download.opensuse.org/repositories/home:p4lang/xUbuntu_${DISTRIB_RELEASE}/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/home_p4lang.gpg > /dev/null && sudo apt-get update && sudo apt install -y p4lang-p4c', quiet = True)\n",
    "stdout, stderr = server1.execute(\"cd /usr/share/p4c/p4include/dpdk/ && sudo sed -i '769s/\\\\(.\\\\{6\\\\}\\\\)/\\\\1out/' pna.p4\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f69d0-28f7-4c03-be6f-c51d0515f872",
   "metadata": {},
   "source": [
    "# Step 5: Implementing the P4-DPDK pipeline\n",
    "This section shows the steps required to implement a P4-DPDK pipeline. It discusses the components needed for the process of compiling, building, and running the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959a3ec-dde7-4ca2-9049-5f05eddd506c",
   "metadata": {},
   "source": [
    "## Step 5.1: Compiling the P4-DPDK pipeline\n",
    "The P4 compiler that will be used is p4c-dpdk, which transforms the P4 code and executes it into a DPDK pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a049f24-3fff-453f-a215-73b502220250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Step 5.1.1: Inspect P4 code\n",
    "Click on [lab1.p4](./labs_files/lab1/lab1.p4) to open the file in the editor.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_01_p4.png\" width=\"300px\"><br>\n",
    "\n",
    "In this lab, we will not modify the P4 code. Instead, we will just compile it using the p4c-dpdk compiler. Note that in this P4 code the Portable NIC Architecture (PNA) is used as shown in the grey box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece4e38-3ecb-4fe3-bb2b-fc7ef09b7d95",
   "metadata": {},
   "source": [
    "### Step 5.1.2: Compile the P4 code\n",
    "To upload and compile the P4 program, issue the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a28c3a-9a46-4e3c-88da-015cbecdf9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0mdpdk\n",
      "lab1.p4\n",
      "lab1.spec\n",
      "nat64.sh\n"
     ]
    }
   ],
   "source": [
    "server1.upload_file('labs_files/lab1/lab1.p4','lab1.p4')\n",
    "stdout, stderr = server1.execute(f'sudo p4c-dpdk --arch=pna lab1.p4 -o lab1.spec')\n",
    "stdout, stderr = server1.execute(f'ls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b286f8d-45a4-4c80-8208-a1bc9dfb0ed4",
   "metadata": {},
   "source": [
    "The command above invokes the ```p4c-dpdk``` compiler to compile the '''lab1.p4''' program which is compatible with the PNA architecture as specified after the ```--arch``` flag. After executing the command, if there are no messages displayed, then the P4 program was compiled successfully. We will see in the printed list the ```lab1.spec``` file, which is a specification file generated by the p4c-dpdk compiler in the current directory as specified after the ```-o``` flag. \n",
    "Now that we have compiled the P4 program and generated the spec file, we can create the P4-DPDK pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18fa6c-2813-47a4-a275-7fc416b6a89c",
   "metadata": {},
   "source": [
    "## Step 5.2: Preparing the P4-DPDK CLI script\n",
    "Each P4-DPDK pipeline is built through the CLI script. In this subsection, we will write the CLI script in which the pipeline is created and built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e544cd-e963-4e2b-9be3-fa132cd8b6ff",
   "metadata": {},
   "source": [
    "Click on [lab1.cli](./labs_files/lab1/lab1.cli) to open the CLI file in the editor.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_02_01.png\" width=\"650px\"><br>\n",
    "We can see that the lab1.cli file is empty and we have to fill it.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We will start by generating the pipeline code and building the shared object. Write the following in the lab1.cli file.\n",
    "\n",
    "    pipeline codegen /home/ubuntu/lab1.spec /tmp/lab1.c\n",
    "    pipeline libbuild /tmp/lab1.c /tmp/lab1.so\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_02_02.png\" width=\"650\"><br>\n",
    "\n",
    "In the figure above the ```codegen``` function (line 2) is used to generate the C code of the compiled user application in the spec file. This function takes two arguments, the path to the specification file compiled ```/home/ubuntu/lab1.spec``` and the generated code is placed in a temporary directory ```/tmp/lab1.c```.\n",
    "\n",
    "The ```libbuild``` function (line 3) is used to generate a shared object to execute the application. This function takes two arguments, the path to the C code ```/tmp/lab1.c``` and the generated shared object is placed in a temporary ```/tmp/lab1.so```.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now we will list the DPDK devices with customized parameters that match our setup. Write the following in the lab1.cli file.\n",
    "\n",
    "    mempool MEMPOOL0 meta 0 pkt 9128 pool 32K cache 256 numa 0\n",
    "    ethdev net_tap0 rxq 1 128 MEMPOOL0 txq 1 512 promiscuous on \n",
    "    ethdev net_tap1 rxq 1 128 MEMPOOL0 txq 1 512 promiscuous on\n",
    "\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_02_03.png\" width=\"650\"><br>\n",
    "\n",
    "The block of code in the figure above (lines 6-8) is used to create DPDK objects like a memory pool mempool and ethernet devices ethdev with parameters to setup each DPDK device.  A memory pool MEMPOOL0 is defined as follows: \n",
    "\n",
    "•\t```mempool```: create a memory pool object associated with a given name. <br>\n",
    "•\t```meta```: specifies the private size of the memory buffer in bytes, which is the memory allocated for an application’s private data.<br>\n",
    "•\t```pkt```: specifies the private size of the memory buffer in bytes, which is the memory allocated for an application to store data associated with a packet.<br>\n",
    "•\t```pool```: the size of the defined memory pool specified in bytes.<br>\n",
    "•\t```cache```: the cache size in bytes which should be a power of 2. <br>\n",
    "•\t```numa```: pinned NUMA node ID.\n",
    "\n",
    "Two ethernet devices which are the interfaces linked to the pipeline, are also defined as net_tap0 and net_tap1 as follows:\n",
    "\n",
    "•\t```ethdev```: ethernet device name (the attached devices net_tap0 and net_tap1 are virtual ethernet devices with their instances created when the pipeline is invoked). <br>\n",
    "•\t```rxq```: receiving queue parameters (number of receiving queues, queue size (bytes), memory pool name).<br>\n",
    "•\t```txq```: transmitting queue parameters (number of transmitting queues, queue size (bytes)). <br>\n",
    "•\t```promiscuous```: A mode that allows a network device to read each network packet that arrives (on / off).<br>\n",
    "\n",
    "<div style=\"background-color: #e0f7fa; border: 1px solid #b2ebf2; padding: 10px; border-radius: 5px;\">\n",
    "It is important that the interface IDs net_tap0 and net_tap1 remain consistent as they will also be used in the I/O specification file and as they will be created while running the pipeline. This is the notation considered by DPDK while the operating system assigns different tags to the interfaces. \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now we will list the P4-DPDK pipelines. Write the following in the lab1.cli file.\n",
    "\n",
    "    pipeline PIPELINE0 build lib /tmp/lab1.so io /home/ubuntu/ethdev.io numa 0\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_02_04.png\" width=\"650\"><br>\n",
    "\n",
    "In the figure above the ```build``` function (line 11) is used to create a pipeline object ```PIPELINE0```. This function takes the path of the shared object library ```lib  /tmp/lab1.so```, the path of the I/O file (which will be discussed in detail in the next subsection) ```io  /home/ubuntu/ethdev.io``` and the numa node ID ```numa  0```.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now we will map the created pipeline to a CPU thread. Write the following in the lab1.cli file.\n",
    "\n",
    "    pipeline PIPELINE0 enable thread 1\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_02_05.png\" width=\"650\"><br>\n",
    "\n",
    "In the figure above the ```enable thread``` function (line 14) is used to map the pipeline ```PIPELINE0``` to the CPU thread ID 1.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Save the changes by pressing ```Ctrl+s```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6bab1-0407-47b4-b3bd-510eae27b2df",
   "metadata": {},
   "source": [
    "## Step 5.3: Preparing the I/O script\n",
    "The stream of packets within a P4-DPDK must be configured. In this subsection, we will write the I/O script which is the configuration file for the pipeline input and output stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62d565-39a2-4c28-98b3-8e7f2d86d8a7",
   "metadata": {},
   "source": [
    "Click on [ethdev.io](./labs_files/lab1/ethdev.io) to open the I/O file in the editor.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_03_01.png\" width=\"650px\"><br>\n",
    "\n",
    "We can see that the ethdev.io file is empty and we have to fill it.\n",
    "\n",
    "<hr>\n",
    "\n",
    "We will start by defining the pipeline input ports. Write the following in the ethdev.io file.\n",
    "\n",
    "    port in 0 ethdev net_tap0 rxq 0 bsz 1\n",
    "    port in 1 ethdev net_tap1 rxq 0 bsz 1\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_03_02.png\" width=\"650px\"><br>\n",
    "\n",
    "Input ports to the pipeline are defined as follows:\n",
    "\n",
    "•\t```port in```: the pipeline input port ID<br>\n",
    "•\t```ethdev```: the ethernet device associated with the defined port<br>\n",
    "•\t```rxq```: the receiving queue ID<br>\n",
    "•\t```bsz```: burst size (packets)<br>\n",
    "\n",
    "In the figure above the ```port in``` function (lines 2-3) is used to define two input ports to the pipeline, each from an interface. In this case, 0 and 1 are assigned as the port IDs of the first and second port respectively. ```net_tap0``` and ```net_tap1``` are both virtual ethernet devices that are associated with ports 0 and 1 respectively. \n",
    "\n",
    "Every packet received at an input port is then forwarded to a receiving queue in the pipeline as determined by the ```rxq``` parameter which holds a value representing the receiving queue ID. Both ports will forward packets to a single queue with ID 0. The ```bsz``` parameter represents the burst size. DPDK attempts to aggregate the cost of processing each packet individually by processing packets in bursts but in this experiment, the burst size is set to 1.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now we will define the pipeline output ports. Write the following in the ethdev.io file.\n",
    "\n",
    "    port out 0 ethdev net_tap0 txq 0 bsz 1\n",
    "    port out 1 ethdev net_tap1 txq 0 bsz 1\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_03_03.png\" width=\"650px\"><br>\n",
    "\n",
    "Output ports to the pipeline are defined as follows:\n",
    "\n",
    "•\t```port out```: the pipeline output port ID<br>\n",
    "•\t```ethdev```: the ethernet device associated with the defined port<br>\n",
    "•\t```txq```: the transmitting queue ID<br>\n",
    "•\t```bsz```: burst size (packets)<br>\n",
    "\n",
    "In the figure above the ```port out``` function (lines 6-7) is used to define two output ports from the pipeline, each to an interface. Similar to the port in function, when this function is called, it is followed by the port ID and ethernet device interface ID. Every packet delivered at an output port is then forwarded to a transmitting queue in the pipeline as determined by the ```txq``` parameter which holds a value representing the transmitting queue ID. Both ports will forward packets to a single queue with ID 0. The burst size ```bsz``` is set to 1.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Save the changes by pressing ```Ctrl+s```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dff360-7ab3-4b31-a3c7-ddb4ad6c1d75",
   "metadata": {},
   "source": [
    "## Step 5.4: Running the P4-DPDK pipeline\n",
    "Now that all the required scripts are prepared, we can run the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd1ce-4bd4-4d91-b1ee-a2cfa03d2a46",
   "metadata": {},
   "source": [
    "### Step 5.4.1: Uploading files\n",
    "The following code uploads the CLI and I/O scripts to server1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "669fc8a7-d84d-4bf1-b22a-fc6ba823f7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SFTPAttributes: [ size=217 uid=1000 gid=1000 mode=0o100664 atime=1726853902 mtime=1726853902 ]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server1.upload_file('labs_files/lab1/lab1.cli','lab1.cli')\n",
    "server1.upload_file('labs_files/lab1/ethdev.io','ethdev.io')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fcd62-45db-4581-bbd1-168c3fea6aee",
   "metadata": {},
   "source": [
    "### Step 5.4.2: Reserving hugepages\n",
    "Configure the number of hugepages in the system by typing the following command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab66bf2-349a-4f26-9a61-b1fefb7a9228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f' sudo sh -c  \"echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8e400-2518-4317-aa34-0219545befaa",
   "metadata": {},
   "source": [
    "Hugepage reservation is done by setting the number of hugepages required to the ```nr_hugepages``` file in the kernel corresponding to a specific page size (in Kilobytes).\n",
    "\n",
    "The ```echo``` command is used to print a value which in this case is ```1024``` representing the number of hugepages. The ```>``` symbol is a redirection operator that redirects the output of the previous command (echo 1024) to the file specified in the following path: ```/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f16db-9b78-4f23-8baa-a5dc51ad8704",
   "metadata": {},
   "source": [
    "### Step 5.4.3: Opening a terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_04_03_terminal.gif\" width=\"800px\"><br>\n",
    "\n",
    "Copy the output of the command below and paste it into the terminal to enter server1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b42fc96-77f5-4049-8aa2-a0d5f73c71ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:468:c00:ffc4:f816:3eff:fe4f:3192'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server1.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f25aaf-85b0-485e-84da-291944f01802",
   "metadata": {},
   "source": [
    "### Step 5.4.4: Running the pipeline\n",
    "\n",
    "Run the following commands in the terminal:\n",
    "    \n",
    "    cd dpdk\n",
    "    sudo examples/pipeline/build/pipeline -c 0x3 --vdev=net_tap0,mac=\"00:00:00:00:00:01\" --vdev=net_tap1,mac=\"00:00:00:00:00:02\" -- -s /home/ubuntu/lab1.cli\n",
    "    \n",
    "<img src=\"./labs_files/lab1/figs/5_04_04.png\" width=\"1000\"><br>\n",
    "\n",
    "In the figure above, the command is used to run the DPDK pipeline application considering the following arguments:\n",
    "\n",
    "•\t```examples/pipeline/build/pipeline```: the path to the executable DPDK pipeline application.<br>\n",
    "•\t```-c```: this parameter is used to specify the hexadecimal bitmask of the cores to run on. In this case, (0x3) indicated that 2 cores are reserved for the pipeline and one extra core is needed for other processes.<br>\n",
    "•\t```--vdev```: this parameter is used to create a virtual device also called a software NIC. Two virtual devices are created, ```net_tap0``` and ```net_tap1```.<br>\n",
    "•\t```mac```: fixed MAC addresses are assigned as ```00:00:00:00:00:01``` for net_tap0 and ```00:00:00:00:00:02``` for net_tap1. (If this parameter is not specified, random MAC addresses will be assigned to the virtual devices).<br>\n",
    "•\t```-s```: this parameter is used to specify the path to the CLI script file to be run at application startup ```/home/ubuntu/lab1.cli```.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a9cf4-3877-490b-b17a-9c90f6c88e16",
   "metadata": {},
   "source": [
    "## Step 5.5: Inspecting interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbef717-b39e-4799-934b-7463f17dae48",
   "metadata": {},
   "source": [
    "### Step 5.5.1: Opening a new terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/5_05_01.gif\" width=\"900px\"><br>\n",
    "\n",
    "Copy the output of the command below and paste it into the terminal to enter server1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f862550a-c7a8-460b-b430-53666e5bcfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:468:c00:ffc4:f816:3eff:fe4f:3192'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server1.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec7b32-f326-434d-ae5c-8895270efcf8",
   "metadata": {},
   "source": [
    "### Step 5.5.2: Inspecting terminals\n",
    "\n",
    "Run the following commands in the terminal:\n",
    "    \n",
    "    ifconfig\n",
    "    \n",
    "<img src=\"./labs_files/lab1/figs/5_05_02.png\" width=\"600px\"><br>\n",
    "\n",
    "We can see that two new interfaces are displayed (highlighted in the grey boxes); ```dtap0``` and ```dtap1```. These interfaces are the interfaces of the virtual devices created earlier net_tap0 and net_tap1. The ```ifconfig``` command displays the names of the interfaces as understood by the operating system. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d4229b-bdfd-456e-baf3-99e1218d55fb",
   "metadata": {},
   "source": [
    "### Step 5.5.3: Inspecting terminals in the pipeline\n",
    "\n",
    "Enter the pipeline CLI by typing the following commands:\n",
    "    \n",
    "    telnet 0.0.0.0 8086\n",
    "    ethdev show\n",
    "    \n",
    "<img src=\"./labs_files/lab1/figs/5_05_03.png\" width=\"400px\"><br>\n",
    "\n",
    "The ```telnet``` command is followed by the broadcast IP address (0.0.0.0) and the port number (8086) to connect to the pipeline.\n",
    "\n",
    "We can see that two interfaces are displayed (highlighted in the grey boxes); ```net_tap0``` and ```net_tap1```. These interfaces are the interfaces of the virtual devices created in the command that runs the pipeline. \n",
    "\n",
    "As we inspect the output for each ethernet device in the figure above, we can see in the first line, that ```ether``` is the MAC addresses assigned to the interfaces while running the pipeline along with ```rxqueues``` and ```txqueues```, the number of receiving and transmitting queues as assigned in the CLI script while listing the ethernet devices. The second line shows the port number ```port#``` as specified in the I/O file. The remaining lines of the output show the received packet count ```RX packets``` and the transmitted packet count ```TX packets``` with the corresponding total byte-count bytes and the number of dropped packets ```misses``` for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f15847-7994-4666-a1a4-168aeeb478d9",
   "metadata": {},
   "source": [
    "### Step 5.5.4: Closing telnet session\n",
    "\n",
    "Close the pipeline CLI and the telnet session by pressing ```ctrl+]```, press ```Enter```, and then type the ```quit``` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c7395-b469-4ebc-9fc3-8f0834ddf676",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 6: Building the experiment topology\n",
    "This section shows the steps required to build the experiment topology shown in the lab topology section. This will be done by creating two Linux namespaces and configuring the interfaces so that a connection between them is established.\n",
    "\n",
    "Namespaces are a feature that partitions Linux resources. Linux namespaces provide independent instances of networks that enable network isolation and independent operations. Each network namespace has its own networking devices, IP addresses, routing tables, and firewall rules [<a href=\"#References\">9</a>]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dca51d-dd1a-48d3-b285-68727e56992c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.1: Create namespaces\n",
    "The following commands create namespaces h1 and h2.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/6_01_namespaces.png\" width=\"550px\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4393bad-397b-4d3d-b16a-a5c735016f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip netns add h1')\n",
    "stdout, stderr = server1.execute(f'sudo ip netns add h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12bb904-a69b-4b39-b2ab-5de2f72cac6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.2: Attaching virtual device interfaces to namespaces\n",
    "The following commands will attach dtap0 to namespace h1 and dtap1 to namespace h2.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/6_02_dtap.png\" width=\"550px\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7856b8b-72ea-4bf1-9040-988a4902e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip link set dtap0 netns h1')\n",
    "stdout, stderr = server1.execute(f'sudo ip link set dtap1 netns h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5baae-10d6-4a5d-b6f9-18f822c577be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.3: Activating virtual device interfaces\n",
    "The following commands will turn up dtap0 on namespace h1 and dtap1 on namespace h2.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/6_03_up.png\" width=\"550px\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91829b56-04e9-42ac-90a0-86d20ceacaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip netns exec h1 ip link set dev dtap0 up')\n",
    "stdout, stderr = server1.execute(f'sudo ip netns exec h2 ip link set dev dtap1 up')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcb5dc-bb89-42c6-87d7-da57daed2dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.4: Assigning IP addresses to the interfaces\n",
    "The following commands will assign the IP address 192.168.10.1 to dtap0 on namespace h1 and 192.168.10.2 to dtap1 on namespace h2.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/6_04_ip.png\" width=\"550px\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8d5be3-554b-4694-91c7-251ca4282a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip netns exec h1 ifconfig dtap0 192.168.10.1/24')\n",
    "stdout, stderr = server1.execute(f'sudo ip netns exec h2 ifconfig dtap1 192.168.10.2/24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740bfac-5354-4484-8bfa-d9beb6456755",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.5: Establishing connection between namespaces\n",
    "The following commands add a static ARP entry to the ARP cache in h1 and h2 to associate the IP addresses in the namespaces to the corresponding MAC addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ce26e6-0df6-4fcd-bbba-01eccc85c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip netns exec h1 arp -s 192.168.10.2 00:00:00:00:00:02')\n",
    "stdout, stderr = server1.execute(f'sudo ip netns exec h2 arp -s 192.168.10.1 00:00:00:00:00:01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321f656-057b-4cce-85a9-12a538279c0c",
   "metadata": {},
   "source": [
    "# Step 7: Testing connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09889acd-e1ba-4f99-bebb-cdcd0ff2f719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7.1: Sending packets from h1 to h2\n",
    "Test the connectivity between namespaces h1 and h2 using the ping command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4682dca-966b-4a5a-a204-68e34989b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING 192.168.10.2 (192.168.10.2) 56(84) bytes of data.\n",
      "64 bytes from 192.168.10.2: icmp_seq=1 ttl=64 time=0.131 ms\n",
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m64 bytes from 192.168.10.2: icmp_seq=2 ttl=64 time=0.081 ms\n",
      "64 bytes from 192.168.10.2: icmp_seq=3 ttl=64 time=0.078 ms\n",
      "64 bytes from 192.168.10.2: icmp_seq=4 ttl=64 time=12.2 ms\n",
      "\n",
      "--- 192.168.10.2 ping statistics ---\n",
      "4 packets transmitted, 4 received, 0% packet loss, time 3075ms\n",
      "rtt min/avg/max/mdev = 0.078/3.110/12.151/5.219 ms\n"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip netns exec h1 ping 192.168.10.2 -c 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f7b1b-0ca8-4bd7-a0ce-5ddb960d257d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7.2: Stopping the DPDK pipeline\n",
    "Stop the DPDK pipeline by pressing ```ctrl+c``` in the terminal running the pipeline.\n",
    "\n",
    "<img src=\"./labs_files/lab1/figs/7_02.png\" width=\"550px\"><br>\n",
    "\n",
    "Note that the logs in the terminal correspond to the code executed for packet processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6dd26-c20c-4c25-96c2-1b2f1aaaeca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 8: Delete the slice\n",
    "\n",
    "This concludes Lab 1. Please delete your slice when you are done with your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f27f3fc-004f-46c2-984c-8c2a90883eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()\n",
    "slice = fablib.get_slice(name=\"P4DPDK_lab1_vnic\")\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e3d97-a261-4c00-984c-2750cbd45064",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "1.\tH. Zhu, “Data Plane Development Kit (DPDK): A Software Optimization Guide to the User Space-based Network Application”, CRC Press, 2020.\n",
    "2.\tR. Donata, “What is DPDK?”, [Online]. Available: https://tinyurl.com/yfc73h7c.\n",
    "3.\tDPDK, “Data Plane Development Kit documentation”, Release 2.2.0, 2016.\n",
    "4.\tIntel, “Introduction to the Data Plane Development Kit (DPDK) Packet Framework”, [Online]. Available: https://tinyurl.com/254r9sc5.\n",
    "5.\tDPDK, “rte_pipeline.h File Reference”, [Online]. Available: https://tinyurl.com/sh9254cs.\n",
    "6.\tS. Ibanez, “The p4-> netfpga workflow for line-rate packet processing”, Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, 2019.\n",
    "7.\tP4lang, “DPDK Backend”, [Online]. Available: https://tinyurl.com/cw29ubxa.\n",
    "8.\tDPDK, “Memory in DPDK, Part 1: General Concepts”, [Online]. Available: https://www.dpdk.org/memory-in-dpdk-part-1-general-concepts/.\n",
    "9.\tToptal, “Separation anxiety: A tutorial for isolating your system with Linux namespaces”, [Online]. Available: https://tinyurl.com/3wm32dbd."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
